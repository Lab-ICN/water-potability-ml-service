{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import boto3\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from xgboost import XGBClassifier\n",
    "import pandas as pd\n",
    "from mlflow.models.signature import infer_signature\n",
    "import urllib3\n",
    "urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(dotenv_path=\"../.env\")\n",
    "\n",
    "access_key = os.getenv(\"AWS_ACCESS_KEY_ID_CLIENT\")\n",
    "secret_key = os.getenv(\"AWS_SECRET_ACCESS_KEY_CLIENT\")\n",
    "s3_url = os.getenv(\"MLFLOW_S3_ENDPOINT_URL_CLIENT\")\n",
    "tracker_url = os.getenv(\"MLFLOW_URL_CLIENT\")\n",
    "os.environ[\"MLFLOW_S3_ENDPOINT_URL\"] = os.getenv(\"MLFLOW_S3_ENDPOINT_URL_CLIENT\")\n",
    "os.environ[\"MLFLOW_TRACKING_USERNAME\"] = os.getenv(\"MLFLOW_ADMIN_USERNAME_CLIENT\")\n",
    "os.environ[\"MLFLOW_TRACKING_PASSWORD\"] = os.getenv(\"MLFLOW_ADMIN_PASSWORD_CLIENT\")\n",
    "os.environ[\"MLFLOW_S3_IGNORE_TLS\"] = \"true\"\n",
    "os.environ[\"MLFLOW_ENABLE_SYSTEM_METRICS_LOGGING\"] = \"true\"\n",
    "bucket_name = \"dataset\"\n",
    "object_name = \"water_potability.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = boto3.client(\n",
    "    's3',\n",
    "    endpoint_url=s3_url,\n",
    "    aws_access_key_id=access_key,\n",
    "    aws_secret_access_key=secret_key,\n",
    "    verify=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # Attempt to list buckets\n",
    "    response = s3.list_buckets()\n",
    "    \n",
    "    # If successful, print bucket names\n",
    "    print(\"Connected successfully! Buckets available:\")\n",
    "    for bucket in response['Buckets']:\n",
    "        print(f\"- {bucket['Name']}\")\n",
    "except Exception as e:\n",
    "    # Print any connection errors\n",
    "    print(\"Connection error:\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    response = s3.get_object(Bucket=bucket_name, Key=object_name)\n",
    "    print(response)\n",
    "    dataset_content = response.get('Body')\n",
    "    print(dataset_content)\n",
    "    df = pd.read_csv(dataset_content)\n",
    "    print(\"Dataset loaded successfully:\")\n",
    "    print(df.head())\n",
    "except Exception as e:\n",
    "    print(\"Error fetching dataset from MinIO:\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = ['ph','Solids','Turbidity','Potability']\n",
    "# feature = ['ph','Solids','Potability']\n",
    "# feature = ['ph','Potability']\n",
    "df = df[feature]\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['Potability']==1].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['Potability']==0].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['Potability']==0].sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['Potability']==1].sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Potability'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df.drop('Potability', axis=1)\n",
    "target = df['Potability']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.combine import SMOTETomek\n",
    "\n",
    "smt = SMOTETomek(random_state=42)\n",
    "data, target = smt.fit_resample(data, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_tracking_uri(tracker_url)\n",
    "experiment_name = \"water_potability\"\n",
    "mlflow.set_experiment(experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = {\n",
    "    \"ph\": \"True\",\n",
    "    \"Hardness\": \"False\",\n",
    "    \"Solids\": \"True\",\n",
    "    \"Chloramines\": \"False\",\n",
    "    \"Sulfate\": \"False\",\n",
    "    \"Conductivity\": \"False\",\n",
    "    \"Organic_carbon\": \"False\",\n",
    "    \"Trihalomethanes\": \"False\",\n",
    "    \"Turbidity\": \"True\",\n",
    "    \"Potability\": \"Binary\",\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model parameters\n",
    "n_estimators = 100\n",
    "max_depth = 5\n",
    "random_state = 42\n",
    "\n",
    "\n",
    "with mlflow.start_run():\n",
    "    # Log parameters\n",
    "    mlflow.log_param(\"n_estimators\", n_estimators)\n",
    "    mlflow.log_param(\"max_depth\", max_depth)\n",
    "    mlflow.log_param(\"random_state\", random_state)\n",
    "\n",
    "    # Initialize and train the model\n",
    "    model = XGBClassifier(n_estimators=n_estimators, max_depth=max_depth, random_state=random_state)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Evaluate the model\n",
    "    predictions = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    mlflow.log_metric(\"accuracy\", accuracy)\n",
    "\n",
    "    # Define input example and signature\n",
    "    input_example = X_test.iloc[:1].fillna(X_test.mean())\n",
    "    signature = infer_signature(X_test, model.predict(X_test))\n",
    "\n",
    "    # Log the model with MLflow\n",
    "    mlflow.sklearn.log_model(\n",
    "        model,\n",
    "        artifact_path=\"model\",\n",
    "        input_example=input_example,\n",
    "        signature=signature\n",
    "    )\n",
    "\n",
    "    # Print run information\n",
    "    run_id = mlflow.active_run().info.run_id\n",
    "    mlflow.set_tags(tags)\n",
    "    mlflow.set_tag(\"Model\", \"XGBoost\")\n",
    "    print(f\"Run ID: {run_id}\")\n",
    "    print(f\"Model accuracy: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "# Model parameters\n",
    "max_iter = 1000\n",
    "pipeline = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"model\", LogisticRegression(max_iter = max_iter))\n",
    "])\n",
    "\n",
    "\n",
    "with mlflow.start_run():\n",
    "    # Log parameters\n",
    "    mlflow.log_param(\"max_iter\", max_iter)\n",
    "\n",
    "    # Initialize and train the model\n",
    "    pipeline.fit(X_train, y_train)\n",
    "\n",
    "    # Evaluate the model\n",
    "    predictions = pipeline.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    mlflow.log_metric(\"accuracy\", accuracy)\n",
    "\n",
    "    # Define input example and signature\n",
    "    input_example = X_test.iloc[:1].fillna(X_test.mean())\n",
    "    signature = infer_signature(X_test, pipeline.predict(X_test))\n",
    "\n",
    "    # Log the model with MLflow\n",
    "    mlflow.sklearn.log_model(\n",
    "        pipeline,\n",
    "        artifact_path=\"model\",\n",
    "        input_example=input_example,\n",
    "        signature=signature\n",
    "    )\n",
    "\n",
    "    # Print run information\n",
    "    run_id = mlflow.active_run().info.run_id\n",
    "    mlflow.set_tags(tags)\n",
    "    mlflow.set_tag(\"Model\", \"Logistic Regression\")\n",
    "    print(f\"Run ID: {run_id}\")\n",
    "    print(f\"Model accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "# Model parameters\n",
    "n_estimators = 100\n",
    "max_depth = 5\n",
    "random_state = 42\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"rf\", RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth, random_state=random_state))\n",
    "])\n",
    "\n",
    "with mlflow.start_run():\n",
    "    # Log parameters\n",
    "    mlflow.log_param(\"n_estimators\", n_estimators)\n",
    "    mlflow.log_param(\"max_depth\", max_depth)\n",
    "    mlflow.log_param(\"random_state\", random_state)\n",
    "    # Initialize and train the model\n",
    "    pipeline.fit(X_train, y_train)\n",
    "\n",
    "    # Evaluate the model\n",
    "    predictions = pipeline.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    mlflow.log_metric(\"accuracy\", accuracy)\n",
    "\n",
    "    # Define input example and signature\n",
    "    input_example = X_test.iloc[:1].fillna(X_test.mean())\n",
    "    signature = infer_signature(X_test, pipeline.predict(X_test))\n",
    "\n",
    "    # Log the model with MLflow\n",
    "    mlflow.sklearn.log_model(\n",
    "        pipeline,\n",
    "        artifact_path=\"model\",\n",
    "        input_example=input_example,\n",
    "        signature=signature\n",
    "    )\n",
    "\n",
    "    # Print run information\n",
    "    run_id = mlflow.active_run().info.run_id\n",
    "    mlflow.set_tags(tags)\n",
    "    mlflow.set_tag(\"Model\", \"Random Forest\")\n",
    "    print(f\"Run ID: {run_id}\")\n",
    "    print(f\"Model accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow.pyfunc\n",
    "\n",
    "model_uri = f\"runs:/{run_id}/model\"\n",
    "model = mlflow.pyfunc.load_model(model_uri)\n",
    "\n",
    "# Check if metadata and signature are available\n",
    "if model.metadata:\n",
    "    print(\"Model signature:\", model.metadata.get_input_schema())\n",
    "else:\n",
    "    print(\"Model metadata is missing.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MLOps",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
